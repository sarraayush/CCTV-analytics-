{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\n\n# path = '/content/video.mp4'\n# Read the video from specified path\ndef video_to_frame(path):\n  cam = cv2.VideoCapture(path)\n\n  try:\n\t\n\t# creating a folder named data\n\t  if not os.path.exists('data'):\n\t\t  os.makedirs('data')\n\n  # if not created then raise error\n  except OSError:\n\t  print ('Error: Creating directory of data')\n\n  # frame\n  currentframe = 0\n\n  while(True):\n\t\n\t  # reading from frame\n\t  ret,frame = cam.read()\n\n\t  if ret:\n\t\t  # if video is still left continue creating images\n\t\t  name = './data/frame' + str(currentframe) + '.jpg'\n\t\t  print ('Creating...' + name)\n\n\t\t  # writing the extracted images\n\t\t  cv2.imwrite(name, frame)\n\n\t\t  # increasing counter so that it will\n\t\t  # show how many frames are created\n\t\t  currentframe += 1\n\t  else:\n\t\t  break\n\n  # Release all space and windows once done\n#   cam.release()\n#   cv2.destroyAllWindows()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:11.367580Z","iopub.execute_input":"2023-04-24T08:44:11.368954Z","iopub.status.idle":"2023-04-24T08:44:11.571656Z","shell.execute_reply.started":"2023-04-24T08:44:11.368609Z","shell.execute_reply":"2023-04-24T08:44:11.570312Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"The above code will break the video into image","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:11.575407Z","iopub.execute_input":"2023-04-24T08:44:11.576363Z","iopub.status.idle":"2023-04-24T08:44:14.732289Z","shell.execute_reply.started":"2023-04-24T08:44:11.576295Z","shell.execute_reply":"2023-04-24T08:44:14.730952Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:14.733611Z","iopub.execute_input":"2023-04-24T08:44:14.733969Z","iopub.status.idle":"2023-04-24T08:44:23.173979Z","shell.execute_reply.started":"2023-04-24T08:44:14.733934Z","shell.execute_reply":"2023-04-24T08:44:23.172191Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:23.175919Z","iopub.execute_input":"2023-04-24T08:44:23.177436Z","iopub.status.idle":"2023-04-24T08:44:23.184442Z","shell.execute_reply.started":"2023-04-24T08:44:23.177384Z","shell.execute_reply":"2023-04-24T08:44:23.183141Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\ndef resize_image(image_path):\n    \"\"\"\n    Resizes an image to 64x64 pixels and saves it under the same filename.\n\n    Args:\n        image_path (str): Path to the image file.\n\n    Returns:\n        None\n    \"\"\"\n    with Image.open(image_path) as img:\n        # Resize the image to 64x64 pixels\n        img_resized = img.resize((64, 64))\n\n        # Save the resized image under the same filename\n        img_resized.save(image_path)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:23.188386Z","iopub.execute_input":"2023-04-24T08:44:23.188989Z","iopub.status.idle":"2023-04-24T08:44:23.195862Z","shell.execute_reply.started":"2023-04-24T08:44:23.188950Z","shell.execute_reply":"2023-04-24T08:44:23.194947Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:23.197187Z","iopub.execute_input":"2023-04-24T08:44:23.197713Z","iopub.status.idle":"2023-04-24T08:44:23.211856Z","shell.execute_reply.started":"2023-04-24T08:44:23.197680Z","shell.execute_reply":"2023-04-24T08:44:23.210661Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"train_dir = \"/kaggle/input/ucf-crime-dataset/Train\"\ntest_dir = \"/kaggle/input/ucf-crime-dataset/Test\"","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:23.213317Z","iopub.execute_input":"2023-04-24T08:44:23.214344Z","iopub.status.idle":"2023-04-24T08:44:23.222993Z","shell.execute_reply.started":"2023-04-24T08:44:23.214292Z","shell.execute_reply":"2023-04-24T08:44:23.221893Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"SEED = 12\nIMG_HEIGHT = 64\nIMG_WIDTH = 64\nBATCH_SIZE = 46      #Was 46\nEPOCHS = 1\nLR =  0.00003\nNUM_CLASSES = 14","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:23.224232Z","iopub.execute_input":"2023-04-24T08:44:23.224553Z","iopub.status.idle":"2023-04-24T08:44:23.234526Z","shell.execute_reply.started":"2023-04-24T08:44:23.224521Z","shell.execute_reply":"2023-04-24T08:44:23.233508Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"CLASS_LABELS = ['Abuse','Arrest','Arson','Assault','Burglary','Explosion','Fighting',\"Normal\",'RoadAccidents','Robbery','Shooting','Shoplifting','Stealing','Vandalism']","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:23.235727Z","iopub.execute_input":"2023-04-24T08:44:23.236605Z","iopub.status.idle":"2023-04-24T08:44:23.247074Z","shell.execute_reply.started":"2023-04-24T08:44:23.236568Z","shell.execute_reply":"2023-04-24T08:44:23.245999Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"preprocess_fun = tf.keras.applications.densenet.preprocess_input","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:23.248522Z","iopub.execute_input":"2023-04-24T08:44:23.249406Z","iopub.status.idle":"2023-04-24T08:44:23.262821Z","shell.execute_reply.started":"2023-04-24T08:44:23.249357Z","shell.execute_reply":"2023-04-24T08:44:23.261799Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n                                   #horizontal_flip=True,\n                                   #width_shift_range=0.1,\n                                   #height_shift_range=0.05,\n                                   rescale = 1./255,\n                                   validation_split=0.2, # set validation split, Added\n                                   preprocessing_function=preprocess_fun\n                                  )\ntest_datagen = ImageDataGenerator(rescale = 1./255,\n                                  preprocessing_function=preprocess_fun\n                                 )","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:23.264156Z","iopub.execute_input":"2023-04-24T08:44:23.264515Z","iopub.status.idle":"2023-04-24T08:44:23.276623Z","shell.execute_reply.started":"2023-04-24T08:44:23.264480Z","shell.execute_reply":"2023-04-24T08:44:23.275127Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = True , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                     subset='training',    #Added\n                                                    seed = SEED\n                                                   )","metadata":{"execution":{"iopub.status.busy":"2023-04-24T08:44:23.278062Z","iopub.execute_input":"2023-04-24T08:44:23.279139Z","iopub.status.idle":"2023-04-24T09:05:09.675014Z","shell.execute_reply.started":"2023-04-24T08:44:23.279089Z","shell.execute_reply":"2023-04-24T09:05:09.673953Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Found 1013081 images belonging to 14 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"validation_generator = train_datagen.flow_from_directory(train_dir, # same directory as training data\n                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = True , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    subset='validation', # set as validation data,  #Added\n                                                    seed = SEED\n                                                   )","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:05:09.676809Z","iopub.execute_input":"2023-04-24T09:05:09.677603Z","iopub.status.idle":"2023-04-24T09:21:48.102899Z","shell.execute_reply.started":"2023-04-24T09:05:09.677553Z","shell.execute_reply":"2023-04-24T09:21:48.101490Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Found 253264 images belonging to 14 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"test_generator = test_datagen.flow_from_directory(directory = test_dir,\n                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n                                                    batch_size = BATCH_SIZE,\n                                                    shuffle  = False , \n                                                    color_mode = \"rgb\",\n                                                    class_mode = \"categorical\",\n                                                    seed = SEED\n                                                  )","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:21:48.107667Z","iopub.execute_input":"2023-04-24T09:21:48.108067Z","iopub.status.idle":"2023-04-24T09:23:50.358082Z","shell.execute_reply.started":"2023-04-24T09:21:48.108013Z","shell.execute_reply":"2023-04-24T09:23:50.357028Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Found 111308 images belonging to 14 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"def feature_extractor(inputs):\n    feature_extractor = tf.keras.applications.DenseNet121(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),\n                                               include_top=False,\n                                               weights=\"imagenet\")(inputs)\n    \n    return feature_extractor","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:23:50.359769Z","iopub.execute_input":"2023-04-24T09:23:50.360327Z","iopub.status.idle":"2023-04-24T09:23:50.366281Z","shell.execute_reply.started":"2023-04-24T09:23:50.360288Z","shell.execute_reply":"2023-04-24T09:23:50.364939Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def classifier(inputs):\n    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(0.5)(x)\n    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n    x = tf.keras.layers.Dropout(0.4) (x)\n    x = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"classification\")(x)\n    \n    return x\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:23:50.367984Z","iopub.execute_input":"2023-04-24T09:23:50.368468Z","iopub.status.idle":"2023-04-24T09:23:50.380629Z","shell.execute_reply.started":"2023-04-24T09:23:50.368420Z","shell.execute_reply":"2023-04-24T09:23:50.379249Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def final_model(inputs):\n    densenet_feature_extractor = feature_extractor(inputs)\n    classification_output = classifier(densenet_feature_extractor)\n    \n    return classification_output\n","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:23:50.382991Z","iopub.execute_input":"2023-04-24T09:23:50.383710Z","iopub.status.idle":"2023-04-24T09:23:50.395776Z","shell.execute_reply.started":"2023-04-24T09:23:50.383672Z","shell.execute_reply":"2023-04-24T09:23:50.394524Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def define_compile_model():\n    \n    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))\n    classification_output = final_model(inputs) \n    model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n     \n    model.compile(optimizer=tf.keras.optimizers.SGD(LR), \n                loss='categorical_crossentropy',\n                metrics = [tf.keras.metrics.AUC()])\n  \n    return model","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:23:50.397355Z","iopub.execute_input":"2023-04-24T09:23:50.398020Z","iopub.status.idle":"2023-04-24T09:23:50.406924Z","shell.execute_reply.started":"2023-04-24T09:23:50.397984Z","shell.execute_reply":"2023-04-24T09:23:50.405838Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"model = define_compile_model()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:23:50.408441Z","iopub.execute_input":"2023-04-24T09:23:50.409082Z","iopub.status.idle":"2023-04-24T09:23:57.677326Z","shell.execute_reply.started":"2023-04-24T09:23:50.409033Z","shell.execute_reply":"2023-04-24T09:23:57.675949Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n29084464/29084464 [==============================] - 2s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:23:57.679043Z","iopub.execute_input":"2023-04-24T09:23:57.679422Z","iopub.status.idle":"2023-04-24T09:23:57.754152Z","shell.execute_reply.started":"2023-04-24T09:23:57.679387Z","shell.execute_reply":"2023-04-24T09:23:57.752793Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n                                                                 \n densenet121 (Functional)    (None, 2, 2, 1024)        7037504   \n                                                                 \n global_average_pooling2d (G  (None, 1024)             0         \n lobalAveragePooling2D)                                          \n                                                                 \n dense (Dense)               (None, 256)               262400    \n                                                                 \n dropout (Dropout)           (None, 256)               0         \n                                                                 \n dense_1 (Dense)             (None, 1024)              263168    \n                                                                 \n dropout_1 (Dropout)         (None, 1024)              0         \n                                                                 \n dense_2 (Dense)             (None, 512)               524800    \n                                                                 \n dropout_2 (Dropout)         (None, 512)               0         \n                                                                 \n classification (Dense)      (None, 14)                7182      \n                                                                 \n=================================================================\nTotal params: 8,095,054\nTrainable params: 8,011,406\nNon-trainable params: 83,648\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(x = train_generator,validation_data=validation_generator,epochs = EPOCHS)","metadata":{"execution":{"iopub.status.busy":"2023-04-24T09:23:57.755922Z","iopub.execute_input":"2023-04-24T09:23:57.756270Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":" 7178/22024 [========>.....................] - ETA: 6:24:31 - loss: 1.3609 - auc: 0.8953","output_type":"stream"}]},{"cell_type":"code","source":"preds = model.predict(test_generator)\ny_test = test_generator.classes\nfig, c_ax = plt.subplots(1,1, figsize = (15,8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n    lb = LabelBinarizer()\n    lb.fit(y_test)\n    y_test = lb.transform(y_test)\n    for (idx, c_label) in enumerate(CLASS_LABELS):\n        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n        c_ax.plot(fpr, tpr,lw=2, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n    c_ax.plot(fpr, fpr, 'black',linestyle='dashed', lw=4, label = 'Random Guessing')\n    return roc_auc_score(y_test, y_pred, average=average)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('ROC AUC score:', multiclass_roc_auc_score(y_test , preds  , average = \"micro\"))\nplt.xlabel('FALSE POSITIVE RATE', fontsize=18)\nplt.ylabel('TRUE POSITIVE RATE', fontsize=16)\nplt.legend(fontsize = 11.5)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"function for image risizing","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\ndef resize_image(image_path):\n    \"\"\"\n    Resizes an image to 64x64 pixels and saves it under the same filename.\n\n    Args:\n        image_path (str): Path to the image file.\n\n    Returns:\n        None\n    \"\"\"\n    with Image.open(image_path) as img:\n        # Resize the image to 64x64 pixels\n        img_resized = img.resize((64, 64))\n\n        # Save the resized image under the same filename\n        img_resized.save(image_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}